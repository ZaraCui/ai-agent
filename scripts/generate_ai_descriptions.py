#!/usr/bin/env python3
"""
ä½¿ç”¨ChatGPT APIç”Ÿæˆå¤šæ ·åŒ–çš„æ™¯ç‚¹æè¿°
Generate diverse spot descriptions using ChatGPT API
"""

import json
import os
import time
from pathlib import Path
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

# å°è¯•å¯¼å…¥OpenAIåº“
try:
    from openai import OpenAI
except ImportError:
    print("âŒ æœªå®‰è£…openaiåº“ï¼Œè¯·è¿è¡Œ: pip install openai")
    exit(1)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
def get_openai_client():
    """è·å–OpenAIå®¢æˆ·ç«¯"""
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key or api_key == 'your_openai_api_key_here':
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")
        print("   è·å–API Key: https://platform.openai.com/api-keys")
        exit(1)
    return OpenAI(api_key=api_key)

# æè¿°é£æ ¼æ¨¡æ¿
DESCRIPTION_STYLES = [
    "ç®€æ´å®ç”¨",  # ç®€æ´ã€ä¿¡æ¯å¯†é›†
    "æ–‡è‰ºä¼˜ç¾",  # ä¼˜ç¾çš„æ–‡å­¦åŒ–æè¿°
    "å†å²æ–‡åŒ–",  # å¼ºè°ƒå†å²æ–‡åŒ–èƒŒæ™¯
    "ç”Ÿæ´»ä½“éªŒ",  # ä»æ¸¸å®¢ä½“éªŒè§’åº¦æè¿°
    "åœ°ç†ç‰¹è‰²",  # å¼ºè°ƒåœ°ç†å’Œè‡ªç„¶ç‰¹è‰²
]

def generate_spot_description(
    client: OpenAI,
    spot: Dict[str, Any],
    city: str,
    style: str = "ç®€æ´å®ç”¨",
    model: str = "gpt-3.5-turbo"
) -> str:
    """
    ä½¿ç”¨ChatGPTç”Ÿæˆæ™¯ç‚¹æè¿°
    
    Args:
        client: OpenAIå®¢æˆ·ç«¯
        spot: æ™¯ç‚¹ä¿¡æ¯å­—å…¸
        city: åŸå¸‚åç§°
        style: æè¿°é£æ ¼
        model: ä½¿ç”¨çš„æ¨¡å‹
    
    Returns:
        ç”Ÿæˆçš„æè¿°æ–‡æœ¬
    """
    name = spot.get('name', '')
    category = spot.get('category', 'sightseeing')
    lat = spot.get('lat', 0)
    lon = spot.get('lon', 0)
    duration = spot.get('duration_minutes', 120)
    
    # ç±»åˆ«ä¸­æ–‡æ˜ å°„
    category_cn = {
        'museum': 'åšç‰©é¦†',
        'history': 'å†å²é—è¿¹',
        'outdoor': 'æˆ·å¤–è‡ªç„¶',
        'sightseeing': 'è§‚å…‰æ™¯ç‚¹',
        'shopping': 'è´­ç‰©',
        'food': 'ç¾é£Ÿ',
        'entertainment': 'å¨±ä¹'
    }.get(category, 'æ™¯ç‚¹')
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""è¯·ä¸ºä»¥ä¸‹æ™¯ç‚¹ç”Ÿæˆä¸€ä¸ªç”ŸåŠ¨ã€å‡†ç¡®ã€æœ‰å¸å¼•åŠ›çš„ä¸­æ–‡æè¿°ï¼ˆ80-150å­—ï¼‰ï¼š

æ™¯ç‚¹åç§°ï¼š{name}
æ‰€åœ¨åŸå¸‚ï¼š{city}
æ™¯ç‚¹ç±»åˆ«ï¼š{category_cn}
å»ºè®®æ¸¸è§ˆæ—¶é—´ï¼š{duration}åˆ†é’Ÿ

è¦æ±‚ï¼š
1. é£æ ¼ï¼š{style}
2. çªå‡ºæ™¯ç‚¹çš„ç‹¬ç‰¹æ€§å’Œç‰¹è‰²
3. æè¿°è¦è‡ªç„¶æµç•…ï¼Œé¿å…æ¨¡æ¿åŒ–
4. åŒ…å«å®ç”¨ä¿¡æ¯ï¼ˆå¦‚é€‚åˆçš„æ¸¸å®¢ç±»å‹ã€æœ€ä½³æ¸¸è§ˆæ—¶é—´ç­‰ï¼‰
5. è¯­è¨€ç”ŸåŠ¨æœ‰è¶£ï¼Œä½†ä¸å¤¸å¼ 
6. ä¸è¦ä½¿ç”¨"è¿™æ˜¯..."ã€"ä½äº..."ç­‰å¼€å¤´
7. ç›´æ¥æè¿°æ™¯ç‚¹æœ¬èº«çš„ç‰¹ç‚¹

è¯·åªè¿”å›æè¿°æ–‡æœ¬ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""

    try:
        # è°ƒç”¨ChatGPT API
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…æ¸¸æ–‡æ¡ˆå†™ä½œä¸“å®¶ï¼Œæ“…é•¿æ’°å†™ç”ŸåŠ¨ã€å‡†ç¡®ã€æœ‰å¸å¼•åŠ›çš„æ™¯ç‚¹æè¿°ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.8,  # å¢åŠ åˆ›é€ æ€§
            max_tokens=300
        )
        
        description = response.choices[0].message.content.strip()
        return description
        
    except Exception as e:
        print(f"  âš ï¸ ç”Ÿæˆæè¿°å¤±è´¥: {e}")
        return spot.get('description', '')

def process_city_spots(
    city: str,
    max_spots: Optional[int] = None,
    style: str = "éšæœº",
    model: str = "gpt-3.5-turbo",
    dry_run: bool = False,
    start_from: int = 0
) -> int:
    """
    å¤„ç†åŸå¸‚çš„æ‰€æœ‰æ™¯ç‚¹
    
    Args:
        city: åŸå¸‚ä»£ç 
        max_spots: æœ€å¤šå¤„ç†çš„æ™¯ç‚¹æ•°é‡
        style: æè¿°é£æ ¼ï¼ˆ"éšæœº"è¡¨ç¤ºéšæœºé€‰æ‹©ï¼‰
        model: ä½¿ç”¨çš„æ¨¡å‹
        dry_run: æ˜¯å¦ä»…é¢„è§ˆä¸ä¿å­˜
        start_from: ä»ç¬¬å‡ ä¸ªæ™¯ç‚¹å¼€å§‹ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
    
    Returns:
        å¤„ç†çš„æ™¯ç‚¹æ•°é‡
    """
    input_path = Path(f'data/spots_{city}.json')
    
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return 0
    
    # åŸå¸‚ä¸­æ–‡åç§°æ˜ å°„
    city_cn_map = {
        'beijing': 'åŒ—äº¬', 'shanghai': 'ä¸Šæµ·', 'shenzhen': 'æ·±åœ³',
        'guangzhou': 'å¹¿å·', 'chengdu': 'æˆéƒ½', 'hangzhou': 'æ­å·',
        'suzhou': 'è‹å·', 'nanjing': 'å—äº¬', 'qingdao': 'é’å²›',
        'xiamen': 'å¦é—¨', 'wuhan': 'æ­¦æ±‰', 'xian': 'è¥¿å®‰',
        'kunming': 'æ˜†æ˜', 'fuzhou': 'ç¦å·', 'changchun': 'é•¿æ˜¥',
        'harbin': 'å“ˆå°”æ»¨', 'shenyang': 'æ²ˆé˜³', 'taiyuan': 'å¤ªåŸ',
        'lanzhou': 'å…°å·', 'xining': 'è¥¿å®', 'urumqi': 'ä¹Œé²æœ¨é½',
        'guiyang': 'è´µé˜³', 'nanning': 'å—å®', 'jinan': 'æµå—',
        'zhengzhou': 'éƒ‘å·', 'hefei': 'åˆè‚¥', 'ningbo': 'å®æ³¢',
        'shijiazhuang': 'çŸ³å®¶åº„', 'foshan': 'ä½›å±±',
        'hongkong': 'é¦™æ¸¯', 'tokyo': 'ä¸œäº¬', 'kyoto': 'äº¬éƒ½',
        'paris': 'å·´é»', 'london': 'ä¼¦æ•¦', 'newyork': 'çº½çº¦',
        'sydney': 'æ‚‰å°¼', 'barcelona': 'å·´å¡ç½—é‚£', 'berlin': 'æŸæ—'
    }
    
    city_cn = city_cn_map.get(city, city.title())
    
    print(f"\n{'='*70}")
    print(f"ğŸ™ï¸  å¤„ç†åŸå¸‚: {city_cn} ({city})")
    print(f"{'='*70}")
    
    # è¯»å–æ•°æ®
    with open(input_path, 'r', encoding='utf-8') as f:
        spots = json.load(f)
    
    total_spots = len(spots)
    print(f"ğŸ“Š æ€»æ™¯ç‚¹æ•°: {total_spots}")
    
    if max_spots:
        spots = spots[:max_spots]
        print(f"ğŸ”¢ æœ¬æ¬¡å¤„ç†: {len(spots)} ä¸ªæ™¯ç‚¹")
    
    if start_from > 0:
        spots = spots[start_from:]
        print(f"â© ä»ç¬¬ {start_from + 1} ä¸ªæ™¯ç‚¹å¼€å§‹")
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    client = get_openai_client()
    
    # å¤„ç†æ¯ä¸ªæ™¯ç‚¹
    processed_count = 0
    import random
    
    for i, spot in enumerate(spots, start=start_from):
        spot_name = spot.get('name', 'Unknown')
        print(f"\n[{i+1}/{total_spots}] å¤„ç†: {spot_name}")
        
        # é€‰æ‹©é£æ ¼
        current_style = style
        if style == "éšæœº":
            current_style = random.choice(DESCRIPTION_STYLES)
            print(f"  é£æ ¼: {current_style}")
        
        # ç”Ÿæˆæ–°æè¿°
        old_description = spot.get('description', '')
        new_description = generate_spot_description(
            client, spot, city_cn, current_style, model
        )
        
        if new_description and new_description != old_description:
            print(f"  âœ… ç”ŸæˆæˆåŠŸ")
            print(f"  æ—§: {old_description[:50]}...")
            print(f"  æ–°: {new_description[:100]}...")
            
            if not dry_run:
                spot['description'] = new_description
                processed_count += 1
            else:
                processed_count += 1
        else:
            print(f"  âš ï¸ æœªç”Ÿæˆæ–°æè¿°")
        
        # é¿å…APIé€Ÿç‡é™åˆ¶
        if i < len(spots) - 1:
            time.sleep(1)  # æ¯ä¸ªè¯·æ±‚é—´éš”1ç§’
    
    # ä¿å­˜
    if not dry_run and processed_count > 0:
        # è¯»å–å®Œæ•´æ•°æ®ï¼ˆå› ä¸ºå¯èƒ½åªå¤„ç†äº†éƒ¨åˆ†ï¼‰
        with open(input_path, 'r', encoding='utf-8') as f:
            all_spots = json.load(f)
        
        # æ›´æ–°å¤„ç†è¿‡çš„æ™¯ç‚¹
        for i, spot in enumerate(spots, start=start_from):
            all_spots[i] = spot
        
        with open(input_path, 'w', encoding='utf-8') as f:
            json.dump(all_spots, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… å·²ä¿å­˜åˆ° {input_path}")
    elif dry_run:
        print(f"\nğŸ” é¢„è§ˆæ¨¡å¼ï¼šæœªä¿å­˜æ›´æ”¹")
    
    return processed_count

def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸ¤– ChatGPTæ™¯ç‚¹æè¿°ç”Ÿæˆå™¨")
    print("="*70)
    print("\næ­¤å·¥å…·å°†ä½¿ç”¨OpenAI APIä¸ºæ™¯ç‚¹ç”Ÿæˆå¤šæ ·åŒ–çš„æè¿°")
    print("æ³¨æ„ï¼šä½¿ç”¨APIä¼šäº§ç”Ÿè´¹ç”¨ï¼Œè¯·ç¡®ä¿å·²è®¾ç½®APIå¯†é’¥\n")
    
    # è·å–æ‰€æœ‰æ™¯ç‚¹æ–‡ä»¶
    data_dir = Path('data')
    spot_files = sorted(data_dir.glob('spots_*.json'))
    
    if not spot_files:
        print("âŒ æœªæ‰¾åˆ°æ™¯ç‚¹æ•°æ®æ–‡ä»¶")
        return
    
    cities = [f.stem.replace('spots_', '') for f in spot_files]
    
    print(f"æ‰¾åˆ° {len(cities)} ä¸ªåŸå¸‚çš„æ™¯ç‚¹æ•°æ®\n")
    
    # é€‰æ‹©åŸå¸‚
    print("è¯·è¾“å…¥è¦å¤„ç†çš„åŸå¸‚ä»£ç ï¼ˆé€—å·åˆ†éš”ï¼Œæˆ–è¾“å…¥'all'å¤„ç†æ‰€æœ‰ï¼‰:")
    print(f"å¯ç”¨åŸå¸‚: {', '.join(cities[:10])}...")
    city_input = input("åŸå¸‚: ").strip().lower()
    
    if city_input == 'all':
        cities_to_process = cities
    else:
        cities_to_process = [c.strip() for c in city_input.split(',')]
    
    # é€‰æ‹©æ•°é‡
    max_spots_input = input("\næ¯ä¸ªåŸå¸‚æœ€å¤šå¤„ç†å¤šå°‘ä¸ªæ™¯ç‚¹ï¼Ÿ(ç•™ç©º=å…¨éƒ¨): ").strip()
    max_spots = int(max_spots_input) if max_spots_input else None
    
    # é€‰æ‹©é£æ ¼
    print("\næè¿°é£æ ¼:")
    for i, s in enumerate(DESCRIPTION_STYLES, 1):
        print(f"  {i}. {s}")
    print(f"  {len(DESCRIPTION_STYLES)+1}. éšæœºï¼ˆæ¨èï¼‰")
    
    style_input = input("é€‰æ‹©é£æ ¼ (1-6): ").strip()
    try:
        style_idx = int(style_input) - 1
        if style_idx == len(DESCRIPTION_STYLES):
            style = "éšæœº"
        else:
            style = DESCRIPTION_STYLES[style_idx]
    except:
        style = "éšæœº"
    
    # é€‰æ‹©æ¨¡å‹
    print("\né€‰æ‹©æ¨¡å‹:")
    print("  1. gpt-3.5-turbo (ä¾¿å®œï¼Œå¿«é€Ÿ)")
    print("  2. gpt-4 (è´¨é‡æ›´é«˜ï¼Œè¾ƒè´µ)")
    print("  3. gpt-4-turbo (å¹³è¡¡é€‰æ‹©)")
    
    model_input = input("é€‰æ‹©æ¨¡å‹ (1-3, é»˜è®¤1): ").strip()
    models = {
        '1': 'gpt-3.5-turbo',
        '2': 'gpt-4',
        '3': 'gpt-4-turbo-preview'
    }
    model = models.get(model_input, 'gpt-3.5-turbo')
    
    # é¢„è§ˆæ¨¡å¼
    dry_run_input = input("\né¢„è§ˆæ¨¡å¼ï¼Ÿ(y/n, é»˜è®¤n): ").strip().lower()
    dry_run = dry_run_input == 'y'
    
    # ç¡®è®¤
    print("\n" + "="*70)
    print("ğŸ“‹ å¤„ç†é…ç½®:")
    print(f"  åŸå¸‚: {', '.join(cities_to_process)}")
    print(f"  æ•°é‡: {'å…¨éƒ¨' if not max_spots else f'æ¯åŸå¸‚{max_spots}ä¸ª'}")
    print(f"  é£æ ¼: {style}")
    print(f"  æ¨¡å‹: {model}")
    print(f"  æ¨¡å¼: {'é¢„è§ˆï¼ˆä¸ä¿å­˜ï¼‰' if dry_run else 'æ­£å¼ï¼ˆä¿å­˜ï¼‰'}")
    print("="*70)
    
    confirm = input("\nç¡®è®¤å¼€å§‹å¤„ç†ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    # å¤„ç†
    total_processed = 0
    for city in cities_to_process:
        if city in cities:
            count = process_city_spots(
                city, 
                max_spots=max_spots,
                style=style,
                model=model,
                dry_run=dry_run
            )
            total_processed += count
        else:
            print(f"âš ï¸ åŸå¸‚ {city} æœªæ‰¾åˆ°")
    
    print("\n" + "="*70)
    print(f"âœ… å®Œæˆï¼å…±å¤„ç† {total_processed} ä¸ªæ™¯ç‚¹æè¿°")
    print("="*70)

if __name__ == '__main__':
    main()
